<!DOCTYPE html><html><head><!-- ! google analytics --><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-W05JEEX90Q"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-W05JEEX90Q');</script><!-- /! google analytics --><!-- ! custom meta tags --><link rel="shortcut icon" href="../favicon.ico" type="image/x-icon"><title>Perceptron | Machine Learning Fundamentals</title><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="author" content="Diego Inácio"><meta property="og:url" content="https://diegoinacio.github.io/machine-learning-notebooks-page/pages/NN_perceptron.html"><meta name="title" property="og:title" content="Perceptron >> Machine Learning Notebooks | Diego Inácio"><meta name="description" property="og:description" content="Overview and implementation of the most fundamental Neural Network model."><meta name="image" property="og:image" content="https://diegoinacio.github.io/machine-learning-notebooks-page/images/thumb_NN_perceptron.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:type" content="article"><meta property="article:author" content="Diego Inácio"><meta property="article:section" content="Machine Learning Notebooks"><!-- /! custom meta tags --><!-- ! custom notebook style --><link rel="stylesheet" href="../assets/css/notebook.css"><!-- /! custom notebook style --><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script><!-- Load mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"></script><!-- MathJax configuration --><script type="text/x-mathjax-config">init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();</script><!-- End of mathjax configuration --></head><body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light"><!-- ! custom navbar --><div class="notebook-navbar"></div><!-- /! custom navbar --><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h1 id="Perceptron">Perceptron<a class="anchor-link" href="#Perceptron">¶</a></h1><hr><ul><li>Author: Diego Inácio</li><li>GitHub: <a href="https://github.com/diegoinacio">github.com/diegoinacio</a></li><li>Notebook: <a href="https://github.com/diegoinacio/machine-learning-notebooks/blob/master/Machine-Learning-Fundamentals/NN_perceptron.ipynb">NN_perceptron.ipynb</a></li></ul><hr><p>Overview and implementation of the most fundamental <em>Neural Network</em> model.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">NN__utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Synthetic data 1 and 2</span>
<span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">synthData1</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">synthData2</span><span class="p">()</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/NN_perceptron_synthData.png" alt="nn perceptron synthdata" title="Neural Network Perceptron Synthetic Data"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><!-- ! google adsense --><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display: block; text-align: center" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-4737780736418859" data-ad-slot="3299263090"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script><!-- /! google adsense --><h2 id="1.-Perceptron">1. Perceptron<a class="anchor-link" href="#1.-Perceptron">¶</a></h2><hr><p>The <em>Perceptron</em> algorithm is very similar to the <em>Logistic Regression</em> one.</p><h3 id="1.1.-Foward-propagation">1.1. Foward propagation<a class="anchor-link" href="#1.1.-Foward-propagation">¶</a></h3><hr>$$ \large Z=w^TX + b $$<p>The activation function (<em>Sigmoid</em>) is: $$ \large \hat{y}=A=\frac{1}{1 + e^{-Z}} $$ The <em>cost</em> function is: $$ \large J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)}) $$</p><!-- ! google adsense --><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display: block; text-align: center" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-4737780736418859" data-ad-slot="3299263090"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script><!-- /! google adsense --><h3 id="1.2.-Backward-propagation">1.2. Backward propagation<a class="anchor-link" href="#1.2.-Backward-propagation">¶</a></h3><hr><p>Gradients: $$ \large \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T$$ $$ \large \frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})$$ where:</p><ul><li>$m$ is the number of examples in the dataset;</li><li>$a^{(i)}$ is the $i_{th}$ component of vector $A$. ### 1.3. Optimization</li></ul><hr><p>The optimization functions is: $$ \large \theta = \theta - \alpha d\theta $$ where $\alpha$ is the <em>learning rage</em>.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Perceptron</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Perceptron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iters</span> <span class="o">=</span> <span class="n">iters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_J</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">J</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_J</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iters</span><span class="p">):</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
            <span class="n">A</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Z</span><span class="p">))</span>
            <span class="n">dw</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">db</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="n">dw</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="n">db</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_J</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">A</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_J</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">a</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">beta</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h2 id="2.-Classification">2. Classification<a class="anchor-link" href="#2.-Classification">¶</a></h2><hr></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="c1"># Perceptron model</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">iters</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>

<span class="c1"># Training and Prediction</span>
<span class="n">p</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">y1_hat</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="n">y2_hat</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>Wall time: 1.81 s
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/NN_perceptron.gif" alt="nn perceptron" title="Neural Network Perceptron"></p></div></div><!-- ! custom footer --><footer class="notebook-footer"></footer><!-- /! custom footer --><!-- ! custom scripts --><script src="../assets/template/notebook.js"></script><!-- /! custom scripts --></body></html>