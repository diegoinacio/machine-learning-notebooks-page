<!DOCTYPE html><html><head><!-- ! google analytics --><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-W05JEEX90Q"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-W05JEEX90Q');</script><!-- /! google analytics --><!-- ! custom meta tags --><link rel="icon" type="image/svg+xml" href="../favicon.svg"><link rel="alternate icon" href="../favicon.ico"><title>Polynomial Regression | Machine Learning Fundamentals</title><meta name="section_name" content="Machine Learning Fundamentals"><meta name="section_id" content="Machine-Learning-Fundamentals"><meta name="notebook_name" content="Polynomial Regression"><meta name="notebook_id" content="regression_polynomial"><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="author" content="Diego Inácio"><meta property="og:url" content="https://diegoinacio.github.io/machine-learning-notebooks-page/pages/regression_polynomial.html"><meta name="title" property="og:title" content="Polynomial Regression >> Machine Learning Notebooks | Diego Inácio"><meta name="description" property="og:description" content="Overview and implementation of Polynomial Regression analysis."><meta name="image" property="og:image" content="https://diegoinacio.github.io/machine-learning-notebooks-page/images/thumb_regression_polynomial.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:type" content="article"><meta property="article:author" content="Diego Inácio"><meta property="article:section" content="Machine Learning Notebooks"><!-- /! custom meta tags --><!-- ! custom notebook style --><link rel="stylesheet" href="../assets/css/notebook-standard.css"><link rel="stylesheet" href="../assets/css/notebook-custom.css"><!-- /! custom notebook style --><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script><!-- Load mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"></script><!-- MathJax configuration --><script type="text/x-mathjax-config">init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();</script><!-- End of mathjax configuration --><!-- ! custom Ko-fi importer --><script type="text/javascript" src="https://storage.ko-fi.com/cdn/widget/Widget_2.js"></script><!-- /! custom Ko-fi importer --></head><body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light"><!-- ! custom navbar --><div class="notebook-navbar"></div><!-- /! custom navbar --><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h1 id="Polynomial-Regression">Polynomial Regression<a class="anchor-link" href="#Polynomial-Regression">¶</a></h1><hr><ul><li>Author: Diego Inácio</li><li>GitHub: <a href="https://github.com/diegoinacio">github.com/diegoinacio</a></li><li>Notebook: <a href="https://github.com/diegoinacio/machine-learning-notebooks/blob/master/Machine-Learning-Fundamentals/regression_polynomial.ipynb">regression_polynomial.ipynb</a></li></ul><hr><p>Overview and implementation of <em>Polynomial Regression</em> analysis.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">regression__utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p>Given the function:</p>$$ \large f(x)=x^3-3x^2+x+1+\epsilon $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Synthetic data 6</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData6</span><span class="p">()</span>

<span class="c1"># Predicting with Linear Regression</span>
<span class="c1"># lrs = linearRegression_simple()</span>
<span class="c1"># lrs.fit(x, y)</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_polynomial_linear.png" alt="polynomial data and linear regression" title="Polynomial data and Linear Regression"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h2 id="Algorithm">Algorithm<a class="anchor-link" href="#Algorithm">¶</a></h2><hr>$$ \large \vec{y}=\mathbf{X}\vec{\mathbf{\beta}}+\vec{\epsilon} $$<p>where $\large \mathbf{X}$ (or $\large \mathbf{V}$) is the <em>Vandermonde's matrix</em> of the independent variable, parametrised by the maximum degree $\large m$, a response vector $\large \vec{y}$, a parameter vector $\large \vec{\mathbf{\beta}}$ and a random error vector $\large \vec{\epsilon}$. In the form of a system of linear equations, we have:</p>$$ \large \begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n \end{bmatrix} = \begin{bmatrix} 1 &amp; x_1 &amp; x_1^2 &amp;\cdots &amp; x_1^m \\ 1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^m \\ 1 &amp; x_3 &amp; x_3^2 &amp; \cdots &amp; x_3^m \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^m \end{bmatrix} \begin{bmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \\ \vdots \\ \beta_m \end{bmatrix} + \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \vdots \\ \epsilon_n \end{bmatrix} $$<p>By means of the Least Squares Method, the estimated coefficient vector is given by:</p>$$ \large \widehat{\vec{\mathbf{\beta}}}=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\vec{y} $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">arraycast</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Decorador para conversão de vetores e matrizes</span>
<span class="sd">    '''</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrap</span>

<span class="k">class</span> <span class="nc">polynomialRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">beta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">VTV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">VTV_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">VTV</span><span class="p">)</span>
        <span class="n">Vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">VTV_i</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Vi</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span><span class="p">)</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p>Notice that our class has an attribute called <em>degree</em> which is the maximum degree of our function $\large f(x)$. In our example it should be $\large m=3$.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">polreg</span> <span class="o">=</span> <span class="n">polynomialRegression</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">polreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>Wall time: 7.99 ms
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_polynomial_pred.png" alt="polynomial regression" title="Polynomial Regression"></p></div></div><!-- ! custom footer --><footer class="notebook-footer"></footer><!-- /! custom footer --><!-- ! custom scripts --><script src="../assets/template/notebook.js"></script><!-- /! custom scripts --></body></html>